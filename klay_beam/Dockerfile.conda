# Example usage:
# docker build -f Dockerfile.conda -t klay-beam:py310 .

# Use two prelimiary images for our multistage build: Apache Beam SDK and Conda.
#
# 1. Apache Beam SDK
#
# We'll use the Beam container to get beam sdk artifacts, which are needed for
# for the beam "worker harness" (the process that connects the execution to the
# job). Note that we still need to pip install the beam SDK in the final image.
#
# Some resources with clues for how to use Beam in a custom container:
# https://cloud.google.com/dataflow/docs/guides/using-custom-containers#use_a_custom_base_image_or_multi-stage_builds
# https://github.com/apache/beam/issues/22349
#
# 2. Conda
#
# We're managing some dependencies conda. We'll build these in a preliminary
# container and copy the resulting artifacts to our runtime container.
#
# A reference for how to do this:
# https://github.com/klay-music/analysis-service/blob/main/Dockerfile


# When launching a Beam job, we must use the same python version to launch the
# job as is used in the we use in the final image. This means that the beam
# invocation (which we'll probably run locally from a command line) must match
# this python version, which also must match the final image.
#
# TLDR:
# PY_VERSION must match the python version specified in environment.yml
ARG PY_VERSION=3.10
# BEAM_VERSION must match the version specified in pyproject.toml
ARG BEAM_VERSION=2.64.0
# Path to the conda lock file as seen by the docker build context
ARG LOCAL_CONDA_LOCK=./environment/py310-torch.linux-64.lock


FROM apache/beam_python${PY_VERSION}_sdk:${BEAM_VERSION} as beam


# Build the conda environment
FROM condaforge/mambaforge:latest as conda
ARG PY_VERSION
ARG BEAM_VERSION
ARG LOCAL_CONDA_LOCK
# Path to the conda lock file in the docker image (relative to WORKDIR)
ARG DOCKER_CONDA_LOCK=./environment/env.lock

WORKDIR /klay/build

# create the conda environment in /env (intalling packages by copying)
COPY ${LOCAL_CONDA_LOCK} ${DOCKER_CONDA_LOCK}
RUN mamba create --copy -p /env --file ${DOCKER_CONDA_LOCK} && conda clean -afy

# Clean in a separate layer as calling conda still generates some __pycache__ files
RUN find -name '*.a' -delete && \
  rm -rf /env/conda-meta && \
  rm -rf /env/include && \
  rm /env/lib/libpython${PY_VERSION}.so.1.0 && \
  find -name '__pycache__' -type d -exec rm -rf '{}' '+' && \
  find /env/lib/python${PY_VERSION}/site-packages/scipy -name 'tests' -type d -exec rm -rf '{}' '+' || : && \
  find /env/lib/python${PY_VERSION}/site-packages/numpy -name 'tests' -type d -exec rm -rf '{}' '+' || : && \
  find /env/lib/python${PY_VERSION}/site-packages/pandas -name 'tests' -type d -exec rm -rf '{}' '+' || : && \
  find /env/lib/python${PY_VERSION}/site-packages -name '*.pyx' -delete


# python:3.10-slim-bullseye comes from debian-11-slim (bullseye)
FROM python:${PY_VERSION}-slim-bullseye

RUN apt-get update -qq && \
  DEBIAN_FRONTEND=noninteractive \
  apt-get install -y --no-install-recommends \
  git git-lfs build-essential \
  libsndfile1 libsndfile1-dev \
  libogg0 libvorbis0a libvorbisenc2 libopus0 \
  libmpg123-0 \
  libflac8 libspeex1 && \
  ldconfig && \
  rm -rf /var/lib/apt/lists/*

ARG PY_VERSION
ARG BEAM_VERSION

# By default, Beam will create a new python virtual environment to run the job.
# Suppress this behavior by setting this environment variable. See:
# https://github.com/apache/beam/blob/65ef48888fa8ee5e4c61cf3eeaf5900f1e8be65b/sdks/python/container/boot.go#L160-L178
#
# Note: this environment variable is supported in apache_beam >= 2.48.0. See:
# https://github.com/apache/beam/blob/master/CHANGES.md#breaking-changes-6
ENV RUN_PYTHON_SDK_IN_DEFAULT_ENVIRONMENT=1

# In Dataflow, when running with GPU support, a volume with GPU drivers will be
# mounted at runtime at /usr/local/nvidia.
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/usr/local/cuda/lib64

# Set the entrypoint to Apache Beam SDK launcher.
ENTRYPOINT ["/opt/apache/beam/boot"]

# Copy files from official SDK image, including script/dependencies.
COPY --from=beam /opt/apache/beam /opt/apache/beam

WORKDIR /klay/app

# Copy the conda environment from the conda build stage
COPY --from=conda /env /env
RUN python$PY_VERSION -m venv /env
RUN . /env/bin/activate
ENV PATH="/env/bin:$PATH"

# Install submodules and klay_beam
COPY . ./klay_beam

# klay_beam lists apache-beam as a dependency, but has a loose version
# requirement. Ensure that the version we install is explicit, and matches the
# source container of our /opt/apache/beam directory.
RUN python3 -m pip install \
  apache-beam[gcp]==${BEAM_VERSION} \
  './klay_beam[code-style, tests, type-check]'

RUN python3 -m pip install build && \
    python3 -m build --wheel ./klay_beam/submodules/klay-data -o ./klay-data-wheel
RUN python3 -m pip install --find-links=./klay-data-wheel 'klay_data[whisper, essentia, torch]'
RUN python3 -m pip install \
  ./klay_beam/submodules/klay-audiotools \
  ./klay_beam/submodules/klay-config \
  ./klay_beam/submodules/klay-nac \
  ./klay_beam/submodules/klay-codecs \
  ./klay_beam/submodules/klay-mtrpp

RUN cd klay_beam && pytest tests/

# Verify that the image does not have conflicting dependencies.
RUN pip check

RUN python3 -c "import torch"
